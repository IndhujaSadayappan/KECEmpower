{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d038ed30-aa5d-4aaa-9eaa-e71697716ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values found in 'Class' column of train dataset. Removing rows with NaN labels.\n",
      "Validation Accuracy: 0.6810\n",
      "Validation Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Abusive       0.67      0.72      0.70       281\n",
      "     Abusive       0.69      0.64      0.67       277\n",
      "\n",
      "    accuracy                           0.68       558\n",
      "   macro avg       0.68      0.68      0.68       558\n",
      "weighted avg       0.68      0.68      0.68       558\n",
      "\n",
      "Predictions saved to 'C:\\Users\\DHARANI SINDHU\\OneDrive\\Documents\\Codelab\\ATRFC001_Predictions.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv('C:\\\\Users\\\\DHARANI SINDHU\\\\OneDrive\\\\Documents\\\\Codelab-docs-1\\\\AWT_train.csv')  # Update with your file path\n",
    "dev_df = pd.read_csv('C:\\\\Users\\\\DHARANI SINDHU\\\\OneDrive\\\\Documents\\\\Codelab-docs-1\\\\AWT_dev.csv')  # Update with your file path\n",
    "test_df = pd.read_csv('C:\\\\Users\\\\DHARANI SINDHU\\\\OneDrive\\\\Documents\\\\Codelab-docs-1\\\\AWT_test_without_labels.csv') # Update with your file path\n",
    "\n",
    "# Preprocess training and development data: Remove rows with missing values\n",
    "train_df.dropna(subset=['Text', 'Class'], inplace=True)  # Remove rows with missing values in Text or Class columns\n",
    "dev_df.dropna(subset=['Text', 'Class'], inplace=True)    # Same for dev dataset\n",
    "\n",
    "# Ensure labels ('Class') are either 1 for 'Abusive' or 0 for 'Non-Abusive'\n",
    "train_df['Class'] = train_df['Class'].map({'Abusive': 1, 'Non-Abusive': 0})\n",
    "dev_df['Class'] = dev_df['Class'].map({'Abusive': 1, 'Non-Abusive': 0})\n",
    "\n",
    "# Check if there are any NaN values in target variable 'Class'\n",
    "if train_df['Class'].isnull().sum() > 0:\n",
    "    print(\"NaN values found in 'Class' column of train dataset. Removing rows with NaN labels.\")\n",
    "    train_df.dropna(subset=['Class'], inplace=True)\n",
    "\n",
    "if dev_df['Class'].isnull().sum() > 0:\n",
    "    print(\"NaN values found in 'Class' column of dev dataset. Removing rows with NaN labels.\")\n",
    "    dev_df.dropna(subset=['Class'], inplace=True)\n",
    "\n",
    "# Prepare the data for TF-IDF vectorization\n",
    "X_train = train_df['Text']\n",
    "y_train = train_df['Class']\n",
    "\n",
    "# Split training data into train and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize text data using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df['Text'])\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_reg_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate on validation data\n",
    "val_predictions = log_reg_model.predict(X_val_tfidf)\n",
    "\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "print(\"Validation Set Classification Report:\")\n",
    "print(classification_report(y_val, val_predictions, target_names=['Non-Abusive', 'Abusive']))\n",
    "\n",
    "# Predict on test data\n",
    "test_predictions = log_reg_model.predict(X_test_tfidf)\n",
    "\n",
    "# Save predictions to the test data\n",
    "test_df['predicted_class'] = test_predictions\n",
    "test_df['predicted_class'] = test_df['predicted_class'].map({0: 'Non-Abusive', 1: 'Abusive'})\n",
    "\n",
    "# Save the test predictions to a CSV file\n",
    "output_file_path = 'C:\\\\Users\\\\DHARANI SINDHU\\\\OneDrive\\\\Documents\\\\Codelab\\\\ATRFC001_Predictions.csv'\n",
    "test_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to '{output_file_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6748ea-e941-4fae-8d0e-21169e44a08b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
